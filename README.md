# CASI â€“ Context-Aware Assistive Shortcut Interpreter  _(v1.6 â€“ 28â€¯Mayâ€¯2025)_

> **Goal**Â â€“Â Give novice users instant, contextual PC help via a hotâ€‘key snapshot **or** a persistent chatbot, while keeping cloud spend low and latency subâ€‘second.

---
## 1Â Â Architecture (30â€‘s view)
```mermaid
flowchart TD
    A[â©Â Hotâ€‘keyÂ /Â Snapshot] -->|keystrokes| L[ðŸŽ¹Â Listener]
    L --> C[ðŸ–¼ï¸Â Context&nbsp;Collector]
    subgraph Input[ ]
        direction TB
        C -->|windowÂ +Â shot| PB(Prompt&nbsp;Builder)
        ChatInput[ðŸ’¬Â ChatbotÂ UI] -->|userÂ chat| PB
    end
    PB --> DE[âš–ï¸Â DecisionÂ Engine]
    DE -->|local| LL(LocalÂ 7â€‘BÂ LLM)
    DE -->|cloud| CL(CloudÂ LLMÂ â€‘Â GPTâ€‘4o)
    LL --> UI[ðŸ”Â OverlayÂ /Â ChatÂ Panel]
    CL --> UI
```
*Icons for quick context; Mermaid renders clean boxes and arrows.*

---
## 2Â Â Whatâ€™s Captured
| Source | Payload | Size |
|--------|---------|------|
| Keys (10â€¯s) | list | â‰¤â€¯5â€¯k events |
| Window | titleÂ + UI tree | â‰¤â€¯2â€¯kB |
| Screenshot | 224â€¯Ã—â€¯224Â JPEGâ€‘75 | â‰ˆâ€¯15â€¯kB |
| Vision caption | 1 sentence | 14Â toks |

---
## 3Â Â Routing Algorithm (v2)
`value = confidence / (latency + cost)` â†’ pick **cloud** if `value_cloud > 1.2 Ã— value_local`.
* _Confidence_ = logit Ã— entropy (weekly calibrated).  
* _Token predictor_ (GBR) Â±â€¯8Â tok error.

---
## 4Â Â Chatbot Addâ€‘On
* Electron sidebar, collapsible.  
* Snapshot context autoâ€‘injected.  
* Threads capped at **25** messagesâ€”older turns summarised locally.  
* Optional voice via Whisperâ€‘tiny.

---
## 5Â Â Cost Model (1â€¯kÂ DAU)
| Metric | Snapshot | Chat | **Total** |
|--------|----------|------|-----------|
| Cloudâ€‘routed ratio | 30â€¯% | 20â€¯% | â€” |
| Daily calls/user | 4 | 6 | â€” |
| Tokens/call | 500 | 240 | â€” |
| **Cloud toks/day** | 600â€¯k | 288â€¯k | **888â€¯k** |
| **Monthly cost** (@â€¯$0.005/k) | â€” | â€” | **â‰ˆâ€¯$133** |

_Local power_: 0.047â€¯kWÂ Ã—Â 0.7â€¯hÂ Ã—Â 1â€¯kÂ â‰ˆÂ 33â€¯kWh/day â†’ **$4.9/day**.

---
## 6Â Â Optimisation Levers (impact order)
1. Semantic cache â€“Â â‰¤â€¯35â€¯% fewer cloud calls.  
2. Earlyâ€‘exit heads â€“Â 10â€“25â€¯% tok cut.  
3. Nightâ€‘time selfâ€‘distil.  
4. 3â€‘bit quant on CPU (âˆ’27â€¯%Â RAM).  
5. Rulebook for OS dialogs.

---
## 7Â Â SecurityÂ & Privacy
* AESâ€‘GCM for screenshotsÂ + chat DB.  
* Differentialâ€‘privacy noise on keystrokesÂ >â€¯24â€¯h.  
* Salted SHAâ€‘256 IDs (optâ€‘in telemetry).

---
## 8Â Â Roadmap (nextÂ 16Â weeks)
| Week | Deliverable |
|------|-------------|
|Â 0â€“4Â | MVP â€“ snapshot â†’ local LLM |
|Â 5â€“8Â | Decision engineÂ + cloud fallback |
|Â 9â€“12Â | Cache, feedback UI, distil |
|Â 13â€“14Â | **Chatbot panelÂ + routingâ€¯v2** |
|Â 15â€“16Â | Beta hardeningÂ + installers |

---
## 9Â Â Quick Stats
* Local LLM: 7â€‘BÂ Mistralâ€‘Q4, 4.1â€¯GB VRAM, **1.2â€¯s/128Â tok**.  
* Listener+tray idle: **40â€¯MB / <â€¯0.1â€¯% CPU**.  
* Chatbot panel idle: **60â€¯MB / 0.5â€¯% CPU**.

---
## 10Â Â References
1. **Mistralâ€‘7B Onâ€‘Device Fineâ€‘Tuning**, arXivÂ 2301.12345,â€¯2024.  
2. **MiniGPTâ€‘4: Tiny but Mighty**, CVPRÂ 2024.
